---
title: "97 things every data engineer should know"
date: "2021-10-07"
author: "Brian Leonard"
pullQuote: "Notes from our book club reading."
image: "97-things-every-data-engineer-should-know/cover.jpeg"
tags: [company]
---

Last month, we decided that we should all read a book and talk about it as a company. It was a fun experience and I think we made a good choice by picking [_97 Things Every Data Engineer Should Know_](https://www.oreilly.com/library/view/97-things-every/9781492062400/).

This was the first book I have read in this [series](https://www.oreilly.com/search/?query=%2297%20Things%22) and I liked the format. It is made up of 97 small vignettes that are 2-3 pages each. This provided a nice overview of the breadth of topics that are relevant to data engineering including data warehouses/lakes, pipelines, metadata, security, compliance, quality, and working with other teams.

<Image
  alt="97 Things Every Data Engineer Should Know"
  src="97-things-every-data-engineer-should-know/cover.jpeg"
  width={300}
  height={450}
  centered
/>

## Themes

I was drawn to the articles that speak to a theme in the data world that I am passionate about: how data pipelines and data team practices are evolving to me more like traditional product development.

Reproducible pipelines

- Automate Your Infrastructure by Christiano Anderson
- Data Pipeline Design Patterns for Reusability and Extensibility by Mukul Sood
- Engineering Reproducible Data Science Projects by Dr. Tianhui Michael Li
- The Three Rs of Data Engineering by Tobias Macey

Data testing and quality

- Automate Your Pipeline Tests by Tom White
- Data Quality for Data Engineers by Katharine Jarmul
- Data Validation Is More Than Summary Statistics by Emily Riederer
- The Six Words That Will Destroy Your Career by Bartosz Mikulski
- Your Data Tests Failed! Now What? by Sam Bail, PhD

Agile development and product management

- Caution: Data Science Projects Can Turn into the Emperor’s New Clothes by Shweta Katre
- Cultivate Good Working Relationships with Data Consumers by Ido Shlomo
- Demystify the Source and Illuminate the Data Pipeline by Meghan Kwartler
- How to Build Your Data Platform like a Product by Barr Moses and Atul Gupte
- Listen to Your Users—but Not Too Much by Amanda Tomlinson
- Tech Should Take a Back Seat for Data Project Success by Andrew Stevenson
- Ten Must-Ask Questions for Data-Engineering Projects by Haidar Hadi
- What to Do When You Don’t Get Any Credit by Jesse Anderson
- When to Talk and When to Listen by Steven Finkelstein

## Feedback

There were a few things that we noticed that could be improved.

The articles are in alphabetical order. I believe it would have been better if they would have had some groupings or take the reader on an arc of some sort. For example, grouping the ones about metadata, discoverability, and column naming might have made a lot of sense.

I read the old-fashioned hard copy, but I was told by people using the Kindle version that the author pictures were of random size. I assume it was the size the authors sent in. This varied from very small to taking over the whole page, creating a disjointed experience. I don't know how such things work, but I feel like [Latex](https://www.latex-project.org/about/) might be involved.

## Notes

I took short notes on the top of each article about it and then copied them to a spreadsheet. Like any good data engineer.

<table className="notesTable">
  <tbody>
    <tr>
      <th>#</th>
      <th>Title</th>
      <th>Notes</th>
    </tr>
    <tr>
      <td>1</td>
      <td>A (Book) Case for Eventual Consistency</td>
      <td>Strong vs eventual consistency</td>
    </tr>
    <tr>
      <td>2</td>
      <td>A/B and How to Be</td>
      <td>
        Most are wrong. If it's working, be skeptical. Test system with A/A
        test.
      </td>
    </tr>
    <tr>
      <td>3</td>
      <td>About the Storage Layer</td>
      <td>Efficiency details for queries</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Analytics as the Secret Glue for Microservice Architectures</td>
      <td>
        What to measure: company metrics, team metrics, experiment metrics
      </td>
    </tr>
    <tr>
      <td>5</td>
      <td>Automate Your Infrastructure</td>
      <td>DevOps is good</td>
    </tr>
    <tr>
      <td>6</td>
      <td>Automate Your Pipeline Tests</td>
      <td>
        Treating data engineering like software engineering. Open question: how
        to seed data in a staging environment?
      </td>
    </tr>
    <tr>
      <td>7</td>
      <td>Be Intentional About the Batching Model in Your Data Pipelines</td>
      <td>Different batching models. Could we do better for Grouparoo?</td>
    </tr>
    <tr>
      <td>8</td>
      <td>Beware of Silver-Bullet Syndrome</td>
      <td>
        Do not build your professional identity on a specific toolset. Be
        adaptable.
      </td>
    </tr>
    <tr>
      <td>9</td>
      <td>Building a Career as a Data Engineer</td>
      <td>Skills: experience on software lifecyle, SQL, open source</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Business Dashboards for Data Pipelines</td>
      <td>Dashboard and graphics help data quality</td>
    </tr>
    <tr>
      <td>11</td>
      <td>
        Caution: Data Science Projects Can Turn into the Emperor’s New Clothes
      </td>
      <td>
        Projects: iterate, provide visibility, env for rapid changes, share
        scripts
      </td>
    </tr>
    <tr>
      <td>12</td>
      <td>Change Data Capture</td>
      <td>
        Should Grouparoo use the WAL or other native CDC approaches? We handle
        the "_deleted" table approach already.
      </td>
    </tr>
    <tr>
      <td>13</td>
      <td>Column Names as Contracts</td>
      <td>Standardize columns names to minimize confusion</td>
    </tr>
    <tr>
      <td>14</td>
      <td>Consensual, Privacy-Aware Data Collection</td>
      <td>
        At some point does Grouparoo get properties noted as PII and what it
        means for a profile to opt out? What does that do?
      </td>
    </tr>
    <tr>
      <td>15</td>
      <td>Cultivate Good Working Relationships with Data Consumers</td>
      <td>Practice empathy</td>
    </tr>
    <tr>
      <td>16</td>
      <td>Data Engineering != Spark</td>
      <td>
        Data eng = Computation + Storage + Messaging + Coding + Architecture +
        Domain Knowledge + Use Cases
      </td>
    </tr>
    <tr>
      <td>17</td>
      <td>Data Engineering for Autonomy and Rapid Innovation</td>
      <td>Sounds like the case of ELT</td>
    </tr>
    <tr>
      <td>18</td>
      <td>Data Engineering from a Data Scientist’s Perspective</td>
      <td>Data engineering has gotten more complex recently</td>
    </tr>
    <tr>
      <td>19</td>
      <td>Data Pipeline Design Patterns for Reusability and Extensibility</td>
      <td>Software design patterns apply to data engineering</td>
    </tr>
    <tr>
      <td>20</td>
      <td>Data Quality for Data Engineers</td>
      <td>
        Implement common sense tests for data quality. What would that look
        like?
      </td>
    </tr>
    <tr>
      <td>21</td>
      <td>Data Security for Data Engineers</td>
      <td>Think about the security of data</td>
    </tr>
    <tr>
      <td>22</td>
      <td>Data Validation Is More Than Summary Statistics</td>
      <td>Quality testing requires context</td>
    </tr>
    <tr>
      <td>23</td>
      <td>Data Warehouses Are the Past, Present, and Future</td>
      <td>Warehouses keep evolving to meet users needs</td>
    </tr>
    <tr>
      <td>24</td>
      <td>Defining and Managing Messages in Log-Centric Architectures</td>
      <td>Standardize message definitions in an evented system</td>
    </tr>
    <tr>
      <td>25</td>
      <td>Demystify the Source and Illuminate the Data Pipeline</td>
      <td>Learn more about the sources of your data</td>
    </tr>
    <tr>
      <td>26</td>
      <td>Develop Communities, Not Just Code</td>
      <td>Think about creating a data culture, not just a pipeline</td>
    </tr>
    <tr>
      <td>27</td>
      <td>Effective Data Engineering in the Cloud World</td>
      <td>There are lots of pieces to work with these days</td>
    </tr>
    <tr>
      <td>28</td>
      <td>Embrace the Data Lake Architecture</td>
      <td>Data lakes are scalable</td>
    </tr>
    <tr>
      <td>29</td>
      <td>Embracing Data Silos</td>
      <td>
        Maybe it's not always right to get your data into one place. If so, find
        a way to abstract the silos to have one way to access it all.
      </td>
    </tr>
    <tr>
      <td>30</td>
      <td>Engineering Reproducible Data Science Projects</td>
      <td>Follow engineering practices to have more dependable proejcts</td>
    </tr>
    <tr>
      <td>31</td>
      <td>Five Best Practices for Stable Data Processing</td>
      <td>Rollback on error, keep data consistent</td>
    </tr>
    <tr>
      <td>32</td>
      <td>Focus on Maintainability and Break Up Those ETL Tasks</td>
      <td>Do one step per transform to maintain simplicity</td>
    </tr>
    <tr>
      <td>33</td>
      <td>Friends Don’t Let Friends Do Dual-Writes</td>
      <td>Use CDC events to write once and then chain to dependencies.</td>
    </tr>
    <tr>
      <td>34</td>
      <td>Fundamental Knowledge</td>
      <td>Knowledge of fundamental concepts allows you to embrace change</td>
    </tr>
    <tr>
      <td>35</td>
      <td>Getting the “Structured” Back into SQL</td>
      <td>Tips on writing SQL.</td>
    </tr>
    <tr>
      <td>36</td>
      <td>Give Data Products a Frontend with Latent Documentation</td>
      <td>Document more to help everyone</td>
    </tr>
    <tr>
      <td>37</td>
      <td>How Data Pipelines Evolve</td>
      <td>Build ELT at mid-range and move to data lakes when you need scale</td>
    </tr>
    <tr>
      <td>38</td>
      <td>How to Build Your Data Platform like a Product</td>
      <td>PM your data with business. Increase visibility.</td>
    </tr>
    <tr>
      <td>39</td>
      <td>How to Prevent a Data Mutiny</td>
      <td>
        Key trends: modular architecture, declarative configuration, automated
        systems
      </td>
    </tr>
    <tr>
      <td>40</td>
      <td>Know the Value per Byte of Your Data</td>
      <td>Check if you are actually using your data</td>
    </tr>
    <tr>
      <td>41</td>
      <td>Know Your Latencies</td>
      <td>
        key questions: how old is data? how fast are queries? how many
        concurrent queries can we handle?
      </td>
    </tr>
    <tr>
      <td>42</td>
      <td>Learn to Use a NoSQL Database, but Not like an RDBMS</td>
      <td>Write answers to questions in NoSQL databases for fast access</td>
    </tr>
    <tr>
      <td>43</td>
      <td>Let the Robots Enforce the Rules</td>
      <td>Work with people to standardize and use code to enforce rules</td>
    </tr>
    <tr>
      <td>44</td>
      <td>Listen to Your Users—but Not Too Much</td>
      <td>
        Create a data team vision and strategy. Take requests and see how they
        fit into that.
      </td>
    </tr>
    <tr>
      <td>45</td>
      <td>Low-Cost Sensors and the Quality of Data</td>
      <td>Order redundant equipment</td>
    </tr>
    <tr>
      <td>46</td>
      <td>Maintain Your Mechanical Sympathy</td>
      <td>Sometimes it helps to understand underlying physics</td>
    </tr>
    <tr>
      <td>47</td>
      <td>Metadata ≥ Data</td>
      <td>Plan your data strategy early and make discovery easy</td>
    </tr>
    <tr>
      <td>48</td>
      <td>Metadata Services as a Core Component of the Data Platform</td>
      <td>Metadata helps discovery, security, and agility</td>
    </tr>
    <tr>
      <td>49</td>
      <td>Mind the Gap: Your Data Lake Provides No ACID Guarantees</td>
      <td>Lakes are not databases</td>
    </tr>
    <tr>
      <td>50</td>
      <td>Modern Metadata for the Modern Data Stack</td>
      <td>Metadata helps collaboration</td>
    </tr>
    <tr>
      <td>51</td>
      <td>Most Data Problems Are Not Big Data Problems</td>
      <td>Most problems are best solved with a relational database</td>
    </tr>
    <tr>
      <td>52</td>
      <td>Moving from Software Engineering to Data Engineering</td>
      <td>Switching from product eng to data eng can. be fun and exciting</td>
    </tr>
    <tr>
      <td>53</td>
      <td>Observability for Data Engineers</td>
      <td>
        Pillars of discoverability: freshness, distribution, volume, schema,
        lineage. "Lineage" sounds useful for Grouparoo.
      </td>
    </tr>
    <tr>
      <td>54</td>
      <td>Perfect Is the Enemy of Good</td>
      <td>Make MVPs and iterate.</td>
    </tr>
    <tr>
      <td>55</td>
      <td>Pipe Dreams</td>
      <td>Kafka was good because it had replaying of messages.</td>
    </tr>
    <tr>
      <td>56</td>
      <td>Preventing the Data Lake Abyss</td>
      <td>
        Use data contracts and tools (Apache Aurora or Google Protocol Buffers)
        to keep lakes under control
      </td>
    </tr>
    <tr>
      <td>57</td>
      <td>Prioritizing User Experience in Messaging Systems</td>
      <td>Realtime data messaging creates better experiences</td>
    </tr>
    <tr>
      <td>58</td>
      <td>Privacy Is Your Problem</td>
      <td>You can often still identify people even when PII is removed</td>
    </tr>
    <tr>
      <td>59</td>
      <td>QA and All Its Sexiness</td>
      <td>
        Testing and QA is good. There are two types: practical and logical.
      </td>
    </tr>
    <tr>
      <td>60</td>
      <td>Seven Things Data Engineers Need to Watch Out for in ML Projects</td>
      <td>Top issue: misunderstanding what a data attribute means.</td>
    </tr>
    <tr>
      <td>61</td>
      <td>Six Dimensions for Picking an Analytical Data Warehouse</td>
      <td>Think about scalability, how it's priced, maintenance, and speed.</td>
    </tr>
    <tr>
      <td>62</td>
      <td>Small Files in a Big Data World</td>
      <td>Having many small files on a system leads to wacky errors</td>
    </tr>
    <tr>
      <td>63</td>
      <td>Streaming Is Different from Batch</td>
      <td>
        You have to think about things differently when streaming instead of
        batching.
      </td>
    </tr>
    <tr>
      <td>64</td>
      <td>Tardy Data</td>
      <td>
        Consider adding meta data column for storage: arrival_time of data to
        know to "go back" and process it.
      </td>
    </tr>
    <tr>
      <td>65</td>
      <td>Tech Should Take a Back Seat for Data Project Success</td>
      <td>
        Focus on self-service and engaging business users to drive successful
        projects
      </td>
    </tr>
    <tr>
      <td>66</td>
      <td>Ten Must-Ask Questions for Data-Engineering Projects</td>
      <td>Understand project parameters before you code</td>
    </tr>
    <tr>
      <td>67</td>
      <td>The Data Pipeline Is Not About Speed</td>
      <td>
        Parallelization is now more important because of cloud horizontal
        scaling
      </td>
    </tr>
    <tr>
      <td>68</td>
      <td>The Dos and Don’ts of Data Engineering</td>
      <td>Do DataOps to make things more reliable and agile, less heroic.</td>
    </tr>
    <tr>
      <td>69</td>
      <td>The End of ETL as We Know It</td>
      <td>Use events from the product to notify data systems of changes.</td>
    </tr>
    <tr>
      <td>70</td>
      <td>The Haiku Approach to Writing Software</td>
      <td>
        Understand constraints, start strong, keep it simple, and be creative.
      </td>
    </tr>
    <tr>
      <td>71</td>
      <td>The Hidden Cost of Data Input/Output</td>
      <td>Storage choices impact performance.</td>
    </tr>
    <tr>
      <td>72</td>
      <td>The Holy War Between Proprietary and Open Source Is a Lie</td>
      <td>
        Use tools that are best for your project and stay out of cargo cults.
      </td>
    </tr>
    <tr>
      <td>73</td>
      <td>The Implications of the CAP Theorem</td>
      <td>Most common trade-off: Speed vs. consistency across nodes.</td>
    </tr>
    <tr>
      <td>74</td>
      <td>The Importance of Data Lineage</td>
      <td>Tracking lineage help answer questions when things go wrong.</td>
    </tr>
    <tr>
      <td>75</td>
      <td>The Many Meanings of Missingness</td>
      <td>
        There are several reasons for a null value. It could be "correct" or an
        error.
      </td>
    </tr>
    <tr>
      <td>76</td>
      <td>The Six Words That Will Destroy Your Career</td>
      <td>
        You lose credibility when the data is wrong. Test and monitor to keep it
        right.
      </td>
    </tr>
    <tr>
      <td>77</td>
      <td>
        The Three Invaluable Benefits of Open Source for Testing Data Quality
      </td>
      <td>Use open source tools to maintain data quality</td>
    </tr>
    <tr>
      <td>78</td>
      <td>The Three Rs of Data Engineering</td>
      <td>
        Data needs to be reliable. Other engineers must be able to reproduce
        your results. Build repeatable infrastructure.
      </td>
    </tr>
    <tr>
      <td>79</td>
      <td>The Two Types of Data Engineering and Data Engineers</td>
      <td>
        Two types of data engineers: SQL (relational databases) and big data
        (python, hadoop)
      </td>
    </tr>
    <tr>
      <td>80</td>
      <td>The Yin and Yang of Big Data Scalability</td>
      <td>
        Complex systems have many knows to be tuned to maximize throughput.
      </td>
    </tr>
    <tr>
      <td>81</td>
      <td>Threading and Concurrency in Data Processing</td>
      <td>You might hit OS limits when scaling servers</td>
    </tr>
    <tr>
      <td>82</td>
      <td>Three Important Distributed Programming Concepts</td>
      <td>
        Concepts: Map/Reduce (Spark, Hadoop), shared memory (Redis), message
        passing (Kafka)
      </td>
    </tr>
    <tr>
      <td>83</td>
      <td>Time (Semantics) Won’t Wait</td>
      <td>
        In event stream processing, there are tradeoffs between completeness and
        latency. Look into watermarks to control.
      </td>
    </tr>
    <tr>
      <td>84</td>
      <td>Tools Don’t Matter, Patterns and Practices Do</td>
      <td>
        Focus on concepts, not tools. Ask "why" questions about new concepts to
        learn.
      </td>
    </tr>
    <tr>
      <td>85</td>
      <td>Total Opportunity Cost of Ownership</td>
      <td>
        Going all in a tool or paradigm might create problems as tech evolves.
      </td>
    </tr>
    <tr>
      <td>86</td>
      <td>Understanding the Ways Different Data Domains Solve Problems</td>
      <td>
        Data science, infra, and eng teams have different goals and mindsets
        that influence their approach.
      </td>
    </tr>
    <tr>
      <td>87</td>
      <td>What Is a Data Engineer? Clue: We’re Data Science Enablers</td>
      <td>
        Data engineers and scientists can work together to produce better
        results
      </td>
    </tr>
    <tr>
      <td>88</td>
      <td>What Is a Data Mesh, and How Not to Mesh It Up</td>
      <td>
        You can have a data lake and many pipelines used by different business
        domains.
      </td>
    </tr>
    <tr>
      <td>89</td>
      <td>What Is Big Data?</td>
      <td>Stay away from hype. Just get the job done.</td>
    </tr>
    <tr>
      <td>90</td>
      <td>What to Do When You Don’t Get Any Credit</td>
      <td>To get credit, talk in terms of business value, not technology</td>
    </tr>
    <tr>
      <td>91</td>
      <td>When Our Data Science Team Didn’t Produce Value</td>
      <td>Balance long-term solutions with short-term needs</td>
    </tr>
    <tr>
      <td>92</td>
      <td>When to Avoid the Naive Approach</td>
      <td>
        Storage format and schema are good to get right from the beginning.
      </td>
    </tr>
    <tr>
      <td>93</td>
      <td>When to Be Cautious About Sharing Data</td>
      <td>
        Maybe everyone shouldn't have access to data that requires expertise to
        interpret.
      </td>
    </tr>
    <tr>
      <td>94</td>
      <td>When to Talk and When to Listen</td>
      <td>Smaller scope helps get things shipped more quickly.</td>
    </tr>
    <tr>
      <td>95</td>
      <td>Why Data Science Teams Need Generalists, Not Specialists</td>
      <td>
        Specialization can slow things down. Lean towards full stack ownership.
      </td>
    </tr>
    <tr>
      <td>96</td>
      <td>With Great Data Comes Great Responsibility</td>
      <td>Consider ethics while building data pipelines.</td>
    </tr>
    <tr>
      <td>97</td>
      <td>Your Data Tests Failed! Now What?</td>
      <td>There are many possible reasons for a failed test.</td>
    </tr>
  </tbody>
</table>

<style>
  {`
    .notesTable {
      width: 100%;
      margin-top: 12px;
      margin-bottom: 20px;
    }    
    
    .notesTable tr:nth-child(odd){
      background-color: #efefef;
    }

    .notesTable tr:first-child {
      background-color: #dedede;
      text-align: center;
      font-weight: bold;
    }

    .notesTable td, th {
      border: 1px solid black;
      padding: 10px;
    }

    .notesTable td:first-child, th:first-child {
      width: 1%;
    }


  `}
</style>
