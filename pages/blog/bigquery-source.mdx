---
title: "BigQuery Source"
date: "2020-05-28"
author: "Brian Leonard"
layout: "blogPage"
pullQuote: "Grouparoo can now connect to your BigQuery warehouse so you can use that data for profile properties."
tags: [connections, engineering]
---

import Image from "../../components/blog/image";

Grouparoo can now connect to your BigQuery warehouse so you can use that data for profile properties. This enables creating groups and automatically syncing that information to your marketing tools.

## Google setup

The setup is similar to the one described [here](google-sheets-source) in the Google Sheets source. You make a "Service Account" and give it access to BigQuery. In this example, I made a "grouparoo-db@sample-sources.iam.gserviceaccount.com" account. Yours will be different. As part of this, you will download a JSON file with credentials.

You then give this account access to your BigQuery database from the [console](https://console.cloud.google.com/bigquery).

<Image
  maxHeight={100}
  alt="Share Dataset"
  src={require("../../public/posts/bigquery-source/google-share-dataset.png")}
/>

<Image
  maxHeight={400}
  alt="Share Dataset"
  src={require("../../public/posts/bigquery-source/google-add-account.png")}
/>

## Create a Grouparoo app

In Grouparoo, you now need to teach the system about your BigQuery setup. This is done through creating an app.

<Image
  maxHeight={400}
  alt="Creating Grouparoo App"
  src={require("../../public/posts/bigquery-source/app-settings.png")}
/>

For BigQuery, this takes in the project and dataset. You paste in the `client_email` and the `private_key` straight from the JSON credentials file. The `private_key` is a bit long, but just go with it. It's ok to include those `\n` characters as-is.

## Create a Grouparoo source

With the app created, you will now have two new new possible sources.

<Image
  maxHeight={200}
  alt="Two new types of sources: query and table"
  src={require("../../public/posts/bigquery-source/source-types.png")}
/>

There are two possible ways to bring in data from BigQuery: Table and Query. Let's talk about each one.

## Table Source

With a BigQuery Table source, the user (often a marketer) can note which data they want to pull in and not have to know how to write the correct SQL.

<Image
  maxHeight={300}
  alt="Pick a table to use"
  src={require("../../public/posts/bigquery-source/table-preview.png")}
/>

You pick which table contains the information you want to make profiles properties from. In this case, I've chosen the `purchases` table, which contains information about which fruits a customer has bought. You can see a preview of the data available.

<Image
  maxHeight={300}
  alt="Make mapping to existing properties"
  src={require("../../public/posts/bigquery-source/table-mapping.png")}
/>

Here we have taught Grouparoo how to map this to profiles that are currently in our system. In this case, the `profile_id` in the table maps to the existing `userId` profiles property.

Now, we can make a profile property from the data in this table. Let's say we want to know their lifetime value (LTV) in fruit purchases. That would look like this:

<Image
  maxHeight={400}
  alt="Create a sum of the purchases made"
  src={require("../../public/posts/bigquery-source/table-property.png")}
/>

We can also add filters here. Maybe we only want their LTV for apples and not all the fruits.

<Image
  maxHeight={150}
  alt="Create another property that filters to specific purchases"
  src={require("../../public/posts/bigquery-source/table-filter.png")}
/>

## Table schedule

An important part of Grouparoo is that these properties we just created will always be up to date. When they are up to date, this changes what groups they are in and what is sent to your destinations.

Grouparoo accomplishes this through creating a schedule. In our Table source case, you only have to teach it which column to use.

<Image
  maxHeight={400}
  alt="Running a schedule to import purchases"
  src={require("../../public/posts/bigquery-source/table-schedule.png")}
/>

In this case, by picking the `stamp` column, when that updates to a newer value (or a new row is added), the respective profiles `LTV` fields will be updated. Now everything is always up to date.

## Query Source

Not every use case can be solved without writing SQL, so Grouparoo also has a way to put whatever query you want to create properties. This can be useful when there are transformations or multiple `JOIN`s needed to get the right data.

While exploring how BigQuery worked, I stumbled across [many public datasets](https://cloud.google.com/bigquery/public-data) that they have. One [example](https://console.cloud.google.com/marketplace/details/social-security-administration/us-names?filter=solution-type:dataset&q=name&id=7a385178-115c-44b0-8ec2-4da800e47888) is information about names in the United States.

<Image
  maxHeight={300}
  alt="Query public names data"
  src={require("../../public/posts/bigquery-source/names-query.png")}
/>

With this information and the Query source, we can make a new property called `guessedGender` that will use the user `firstName` property value. Here's the query we will use:

```
SELECT gender FROM`bigquery-public-data.usa_names.usa_1910_current`WHERE LOWER(name) = LOWER('{{ firstName }}') GROUP BY gender ORDER BY SUM(number) DESC`
```

<Image
  maxHeight={300}
  alt="Profile property rule"
  src={require("../../public/posts/bigquery-source/query-property.png")}
/>

## Results

At this point, we can see the profile properties that have been created in each profile.

<Image
  maxHeight={400}
  alt="Profile has the data from BigQuery"
  src={require("../../public/posts/bigquery-source/profile.png")}
/>

And you can also use it to make groups.

<Image
  maxHeight={300}
  alt="Groups can use the data from BigQuery"
  src={require("../../public/posts/bigquery-source/group.png")}
/>

This data can be sent to destinations like Mailchimp.

## Implementation Details

The largest challenge with BigQuery was around the syntax for the Table source. The SQL engines we have implemented (Postgres, MySQL) handle typing a bit more gracefully. Specifically, you can send a quoted integer to a `INT` Postgres column and it will still work. For example: `SELECT * FROM users WHERE age = '22'`. This same query one BigQuery would cause a type error because `age` is a numerical column.

What this means for the implementation is that the code has to be much more sure about all the types involved. In the end this makes the implementation much smarter, but it took lots of [testing](https://github.com/grouparoo/grouparoo/blob/master/plugins/%40grouparoo/bigquery/__tests__/table-import/import-property.ts) to handle all the combinatorics involved. It also made it slower because we are checking the types a lot. I will likely go back and add some caching in next.

There are also 4 different kinds of date-ish column types involved:

- `TIMESTAMP`: an exact moment in a specific timezone which can be represented by an epoch time.
- `DATETIME`: a date and time, but it doesn't not have a timezone. `2020-05-01 12:00` could be noon on that day in any timezone.
- `DATE`: just a date, again in relative timezones.
- `TIME`: just a time like `12:00` without a date, maybe for a property like "preferred contact time"

How to represent these in Grouparoo and Javascript is an interesting question. The `TIMESTAMP` one maps fairly well to the `Date` Javascript object, but the others are up for discussion. I'd be happy for input.

Overall, BigQuery maps quite well to the Grouparoo model and I'm excited to start getting some of its data flowing through the pipes.
